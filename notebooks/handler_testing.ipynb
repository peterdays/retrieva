{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0186730b-3ba8-46e8-881f-ab5b101e4edd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-24T02:09:17.661142Z",
     "iopub.status.busy": "2024-04-24T02:09:17.660713Z",
     "iopub.status.idle": "2024-04-24T02:09:17.701003Z",
     "shell.execute_reply": "2024-04-24T02:09:17.699853Z",
     "shell.execute_reply.started": "2024-04-24T02:09:17.661102Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44583222-8845-40e9-af52-8519f2d3adf6",
   "metadata": {},
   "source": [
    "# testing the handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd2cb59f-262d-450e-8ac6-c4670d7bf448",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-24T02:09:18.150801Z",
     "iopub.status.busy": "2024-04-24T02:09:18.150326Z",
     "iopub.status.idle": "2024-04-24T02:09:22.471415Z",
     "shell.execute_reply": "2024-04-24T02:09:22.470687Z",
     "shell.execute_reply.started": "2024-04-24T02:09:18.150760Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peterdays/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from retrieva.handler import RagHandler\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from retrieva import ROOT_PATH\n",
    "# used in dev; in production pass the env variable to the containers\n",
    "load_dotenv(os.path.join(ROOT_PATH, \".env\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a944f12-3a7e-49e7-a979-0a0da492bf6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-24T02:09:22.472919Z",
     "iopub.status.busy": "2024-04-24T02:09:22.472556Z",
     "iopub.status.idle": "2024-04-24T02:09:22.515273Z",
     "shell.execute_reply": "2024-04-24T02:09:22.514534Z",
     "shell.execute_reply.started": "2024-04-24T02:09:22.472897Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display, clear_output\n",
    "\n",
    "# define prompt viewing function\n",
    "def display_prompt_dict(prompts_dict):\n",
    "    for k, p in prompts_dict.items():\n",
    "        text_md = f\"**Prompt Key**: {k}<br>\" f\"**Text:** <br>\"\n",
    "        display(Markdown(text_md))\n",
    "        print(p.get_template())\n",
    "        display(Markdown(\"<br><br>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75b8f07c-a56e-4682-b199-411ab84abccf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-24T02:09:22.516178Z",
     "iopub.status.busy": "2024-04-24T02:09:22.515980Z",
     "iopub.status.idle": "2024-04-24T02:09:22.603617Z",
     "shell.execute_reply": "2024-04-24T02:09:22.602745Z",
     "shell.execute_reply.started": "2024-04-24T02:09:22.516161Z"
    }
   },
   "outputs": [],
   "source": [
    "from retrieva.data import add_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d970beb4-8eca-4c15-a374-512253e11469",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-24T02:09:58.105533Z",
     "iopub.status.busy": "2024-04-24T02:09:58.105238Z",
     "iopub.status.idle": "2024-04-24T02:10:07.808950Z",
     "shell.execute_reply": "2024-04-24T02:10:07.807921Z",
     "shell.execute_reply.started": "2024-04-24T02:09:58.105507Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-24 03:09:58,170 | INFO | handler - __init__() \n",
      ">>>> Using weaviate db at http://localhost:10080\n",
      "\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: BAAI/bge-small-en-v1.5\n",
      "Load pretrained SentenceTransformer: BAAI/bge-small-en-v1.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peterdays/miniconda3/envs/retrieva/lib/python3.10/site-packages/weaviate/warnings.py:121: DeprecationWarning: Dep005: You are using weaviate-client version 3.26.2. The latest version is 4.5.6.\n",
      "            Please consider upgrading to the latest version. See https://weaviate.io/developers/weaviate/client-libraries/python for details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cuda\n",
      "Use pytorch device_name: cuda\n",
      "2024-04-24 03:10:07,770 | INFO | handler - __init__() \n",
      ">>>> Loading SageMakerDocs...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rag_handler = RagHandler(\n",
    "    index_name=\"SageMakerDocs\",\n",
    "    weaviate_url=os.environ[\"WEAVIATE_URL\"],\n",
    "    data_path=add_root(os.environ[\"DATA_FOLDER_PATH\"]),\n",
    "    cloud_based=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46da3d44-f3be-42e9-9f04-0dfe647c4e18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-24T02:13:30.366467Z",
     "iopub.status.busy": "2024-04-24T02:13:30.365554Z",
     "iopub.status.idle": "2024-04-24T02:13:31.070069Z",
     "shell.execute_reply": "2024-04-24T02:13:31.069361Z",
     "shell.execute_reply.started": "2024-04-24T02:13:30.366434Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# testing\n",
    "query = \"how can I solve a RL aws problem with sagemaker?\"\n",
    "# query = \"do you know anything about sagemkaer toolkit?\"\n",
    "# query = \"am I an OVNI?\"\n",
    "resp_stream = rag_handler.user_prompt_streaming(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbbdef93-4428-4a18-a378-5bc4ede83c3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-24T02:13:33.123172Z",
     "iopub.status.busy": "2024-04-24T02:13:33.122837Z",
     "iopub.status.idle": "2024-04-24T02:15:14.834429Z",
     "shell.execute_reply": "2024-04-24T02:15:14.833969Z",
     "shell.execute_reply.started": "2024-04-24T02:13:33.123138Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context information, it seems that SageMaker is a machine learning service offered by AWS (Amazon Web Services). It provides tools for training and deploying machine learning models. In your query about solving a reinforcement learning (RL) problem with SageMaker, I can suggest the following steps:\n",
      "\n",
      "1. Check if SageMaker supports RL algorithms. The documentation provided in the context information doesn't mention RL explicitly, but it does list various machine learning tasks that can be performed using SageMaker, such as image and text classification, object detection, and regression. You may want to check the official SageMaker documentation for more details on supported algorithms and workflows.\n",
      "\n",
      "2. If SageMaker supports RL, you'll need to create a new SageMaker project and follow the steps outlined in the documentation to set up your environment, including installing required dependencies and configuring your training script.\n",
      "\n",
      "3. You can use the SageMaker Training and Inference Toolkits mentioned in the context information to adapt your RL container for deployment on SageMaker. This involves specifying the location of your code, defining an entry point, and providing other necessary information.\n",
      "\n",
      "4. Once you've trained your model, you can deploy it using SageMaker's hosting options or as a real-time inference endpoint.\n",
      "\n",
      "5. Finally, you may want to consider using Application Auto Scaling and Service-linked roles for optimizing resource usage and managing access control, respectively. These features are also mentioned in the context information.\n",
      "\n",
      "I hope this helps you get started with solving your RL problem using SageMaker! Remember to always refer to the official documentation for detailed guidance and best practices.\n"
     ]
    }
   ],
   "source": [
    "sentence = \"\"\n",
    "for text in resp_stream.response_gen:\n",
    "    # return the texts as they arrive.\n",
    "    clear_output()\n",
    "    sentence += text\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c104939-a75c-4fd7-abf3-16070f4ea780",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-24T02:15:17.685486Z",
     "iopub.status.busy": "2024-04-24T02:15:17.684893Z",
     "iopub.status.idle": "2024-04-24T02:15:22.109535Z",
     "shell.execute_reply": "2024-04-24T02:15:22.108477Z",
     "shell.execute_reply.started": "2024-04-24T02:15:17.685432Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Prompt Key**: response_synthesizer:text_qa_template<br>**Text:** <br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context information is below.\n",
      "---------------------\n",
      "{context_str}\n",
      "---------------------\n",
      "Given the context information and not prior knowledge, answer the query.\n",
      "Query: {query_str}\n",
      "Answer: \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Prompt Key**: response_synthesizer:refine_template<br>**Text:** <br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original query is as follows: {query_str}\n",
      "We have provided an existing answer: {existing_answer}\n",
      "We have the opportunity to refine the existing answer (only if needed) with some more context below.\n",
      "------------\n",
      "{context_msg}\n",
      "------------\n",
      "Given the new context, refine the original answer to better answer the query. If the context isn't useful, return the original answer.\n",
      "Refined Answer: \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompts_dict = rag_handler.engine.get_prompts()\n",
    "display_prompt_dict(prompts_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10300f96-b584-4ee3-b898-dbc955c98bcb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
